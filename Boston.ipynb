{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bbb6cbf",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbe0cea9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "def encode_categorical(df):\n",
    "    label_encoder = LabelEncoder()\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column] = label_encoder.fit_transform(df[column])\n",
    "        elif df[column].dtype == 'float64' or df[column].dtype == 'int64':\n",
    "            df[column] = df[column].fillna(df[column].mean())\n",
    "    return df\n",
    "\n",
    "df1 = pd.read_csv('train.csv')\n",
    "df1 = encode_categorical(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581c6a17",
   "metadata": {},
   "source": [
    "### Building dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f262afc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1168"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch.utils.data as Data\n",
    "import torch\n",
    "\n",
    "\n",
    "batch_sizes = 32\n",
    "\n",
    "x = df1.iloc[:,1:-1]\n",
    "y= df1.iloc[:,-1:]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2004)\n",
    "\n",
    "x_train_tensor = torch.FloatTensor(x_train.values)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values)\n",
    "x_test_tensor = torch.FloatTensor(x_test.values)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values)\n",
    "\n",
    "train_dataset = Data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = Data.TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "train_dataloader = Data.DataLoader(train_dataset,batch_sizes,shuffle=True)\n",
    "test_dataloader = Data.DataLoader(test_dataset,batch_sizes,shuffle=True)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74eed53",
   "metadata": {},
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a45ed41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(in_features, 40)  # nn.Module\n",
    "        self.linear_2 = nn.Linear(40, 10)\n",
    "        self.linear_3 = nn.Linear(10, out_features)\n",
    "        self.sigmoid = nn.Sigmoid()  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "#         x = self.sigmoid(x)  \n",
    "        x = self.linear_2(x)\n",
    "#         x = self.sigmoid(x)\n",
    "        x = self.linear_3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c0a17c",
   "metadata": {},
   "source": [
    "### Parameter determination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e11e4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LinearNet(79,1).to(device)\n",
    "loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e19643f",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd714e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model,dataloader):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    for idx,(x,y) in enumerate(dataloader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(x)\n",
    "        cur_loss = loss(y_pred,y)\n",
    "        optimizer.zero_grad()\n",
    "        cur_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += cur_loss.item()\n",
    "    print(f\"train loss:{total_loss/len(train_dataset)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcd3b99",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4aff9460",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_model(model, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.\n",
    "    for idx, (x, y) in enumerate(dataloader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(x)\n",
    "        cur_loss = loss(y_pred, y)\n",
    "        total_loss += cur_loss.item()\n",
    "    print(f\"Test loss: {total_loss/len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d04abf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a7fc4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Epoch 0 ====\n",
      "train loss:1177021904.6575344\n",
      "Test loss: 1366200754.8493152\n",
      "==== Epoch 1 ====\n",
      "train loss:1067317121.7534246\n",
      "Test loss: 1084767996.4931507\n",
      "==== Epoch 2 ====\n",
      "train loss:745308767.5616438\n",
      "Test loss: 643709794.1917808\n",
      "==== Epoch 3 ====\n",
      "train loss:374429088.2191781\n",
      "Test loss: 323084168.7671233\n",
      "==== Epoch 4 ====\n",
      "train loss:226155368.98630136\n",
      "Test loss: 235693242.30136988\n",
      "==== Epoch 5 ====\n",
      "train loss:203073137.42465752\n",
      "Test loss: 242013528.5479452\n",
      "==== Epoch 6 ====\n",
      "train loss:187340298.95890412\n",
      "Test loss: 218652483.50684932\n",
      "==== Epoch 7 ====\n",
      "train loss:176701946.30136988\n",
      "Test loss: 206658525.80821916\n",
      "==== Epoch 8 ====\n",
      "train loss:176453687.23287672\n",
      "Test loss: 203325671.4520548\n",
      "==== Epoch 9 ====\n",
      "train loss:155728964.49315068\n",
      "Test loss: 205692983.67123288\n",
      "==== Epoch 10 ====\n",
      "train loss:147139885.26027396\n",
      "Test loss: 207025205.9178082\n",
      "==== Epoch 11 ====\n",
      "train loss:139402169.6438356\n",
      "Test loss: 189641487.78082192\n",
      "==== Epoch 12 ====\n",
      "train loss:133565097.20547946\n",
      "Test loss: 165795030.13698632\n",
      "==== Epoch 13 ====\n",
      "train loss:128163031.34246576\n",
      "Test loss: 165990997.04109588\n",
      "==== Epoch 14 ====\n",
      "train loss:123678427.7260274\n",
      "Test loss: 177250787.94520548\n",
      "==== Epoch 15 ====\n",
      "train loss:119045021.42465754\n",
      "Test loss: 152430388.60273972\n",
      "==== Epoch 16 ====\n",
      "train loss:115149599.78082192\n",
      "Test loss: 156280836.8219178\n",
      "==== Epoch 17 ====\n",
      "train loss:109821496.5479452\n",
      "Test loss: 283565987.5068493\n",
      "==== Epoch 18 ====\n",
      "train loss:107681029.15068494\n",
      "Test loss: 145394152.76712328\n",
      "==== Epoch 19 ====\n",
      "train loss:103119916.8219178\n",
      "Test loss: 156526302.68493152\n",
      "==== Epoch 20 ====\n",
      "train loss:100148649.20547946\n",
      "Test loss: 143870833.97260273\n",
      "==== Epoch 21 ====\n",
      "train loss:97967185.26027398\n",
      "Test loss: 142753582.02739727\n",
      "==== Epoch 22 ====\n",
      "train loss:96117397.47945206\n",
      "Test loss: 147782882.19178084\n",
      "==== Epoch 23 ====\n",
      "train loss:94883983.89041096\n",
      "Test loss: 134864911.78082192\n",
      "==== Epoch 24 ====\n",
      "train loss:89609031.01369864\n",
      "Test loss: 135787115.83561644\n",
      "==== Epoch 25 ====\n",
      "train loss:87785355.89041096\n",
      "Test loss: 126982955.83561644\n",
      "==== Epoch 26 ====\n",
      "train loss:85272129.15068494\n",
      "Test loss: 129692160.43835616\n",
      "==== Epoch 27 ====\n",
      "train loss:83057369.3150685\n",
      "Test loss: 127743459.50684932\n",
      "==== Epoch 28 ====\n",
      "train loss:81227655.67123288\n",
      "Test loss: 122515096.76712328\n",
      "==== Epoch 29 ====\n",
      "train loss:79957813.26027398\n",
      "Test loss: 124278122.9589041\n",
      "==== Epoch 30 ====\n",
      "train loss:77531516.93150684\n",
      "Test loss: 118820608.87671232\n",
      "==== Epoch 31 ====\n",
      "train loss:75433324.32876712\n",
      "Test loss: 117848205.36986302\n",
      "==== Epoch 32 ====\n",
      "train loss:74743803.78082192\n",
      "Test loss: 116201696.43835616\n",
      "==== Epoch 33 ====\n",
      "train loss:72665677.09589042\n",
      "Test loss: 115277918.46575342\n",
      "==== Epoch 34 ====\n",
      "train loss:70120283.61643836\n",
      "Test loss: 120765006.02739726\n",
      "==== Epoch 35 ====\n",
      "train loss:68294604.8219178\n",
      "Test loss: 113703831.01369864\n",
      "==== Epoch 36 ====\n",
      "train loss:67178025.5890411\n",
      "Test loss: 112364092.49315068\n",
      "==== Epoch 37 ====\n",
      "train loss:65829091.61643836\n",
      "Test loss: 121846824.76712328\n",
      "==== Epoch 38 ====\n",
      "train loss:64611086.95890411\n",
      "Test loss: 138153964.49315068\n",
      "==== Epoch 39 ====\n",
      "train loss:62429879.28767123\n",
      "Test loss: 115912855.89041096\n",
      "==== Epoch 40 ====\n",
      "train loss:61442437.69863014\n",
      "Test loss: 112604754.84931506\n",
      "==== Epoch 41 ====\n",
      "train loss:60396406.19178082\n",
      "Test loss: 111097797.26027398\n",
      "==== Epoch 42 ====\n",
      "train loss:59345446.49315068\n",
      "Test loss: 109742035.39726028\n",
      "==== Epoch 43 ====\n",
      "train loss:57482367.7260274\n",
      "Test loss: 113428098.84931506\n",
      "==== Epoch 44 ====\n",
      "train loss:57143495.67123288\n",
      "Test loss: 123852192.0\n",
      "==== Epoch 45 ====\n",
      "train loss:55901863.23287671\n",
      "Test loss: 113484958.02739726\n",
      "==== Epoch 46 ====\n",
      "train loss:54624580.02739726\n",
      "Test loss: 112772670.6849315\n",
      "==== Epoch 47 ====\n",
      "train loss:54033063.12328767\n",
      "Test loss: 110091643.42465754\n",
      "==== Epoch 48 ====\n",
      "train loss:53107635.83561644\n",
      "Test loss: 114338310.57534246\n",
      "==== Epoch 49 ====\n",
      "train loss:52445528.2739726\n",
      "Test loss: 115639222.57534246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAERCAYAAACO6FuTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYk0lEQVR4nO3dfZRcdZ3n8fcXEkgGFHnIhsUYA5KJQpQHGycRNrYZwoQ5rudMBEVY2IgEdIWR3WVHlAfjDMrujsuIIIOBEHbgiIIKwzgbyCjbJiiRSeRBnhRYgyYQiEkQw4NG/O4fdZs0oX7d1d1V1Q95v87pk6pb33vv91eVrk/97u2+HZmJJEn17DTUDUiShi9DQpJUZEhIkooMCUlSkSEhSSoyJCRJRYbEKBQR50TE+oh4MSJ+Xd1+7yC3d06r6tslIroiorOXxz9UPVdbqq/1EXFKG/qaHxFfb/V+houIWNjj+V0fEeubvP1eX2f1z5ihbkDNl5lfBL4YEdcCKzPzyiZsr2X1w0VmfgP4RkQsBMZl5rmD2V5ELMzMhc3obRS6fLDPr9rDmYTUOp8d6gakwTIkdjDVVPy4iLglIu7osfxjEfGLiFgXEZ/abp2F1afr7vud1Xb+V0T8KiKWR8T4gdRHxAkRsTYifhwRX4+Ia/ro/zV99rH9CyPiqYhYCrx+EM/bn0fEIxHx9HZjOyMifhkRz0TERdWy/9F9CKU6nPLgIPb736rx/jQijq2W7RQRi6px/SIi/qK35b1se6fqOVsXEfdFxBHV8psi4n3V7V2r7e0aEWMi4ksR8WT1XMzosa2MiMMjYlVE/M0Ax9oVEddXz+fqiPjjavkfRcS1VR93RsSB1fJ9IuIfq+f+BxGxf4/NvaMa08aI+HBV/2+qfTwdEfdGxFsH0ueOxpDYMX0BuAbofnMZB5wMzACmAudExO59bGMm8HPg31J78507wPpLgT8Fvgr8PjNPLW2gjz5fs/2IeBdwKnAQcCFwSB89lvY7AbgMOAY4EDg+Ig6rHv5b4FhgMjAtIl6XmZ/KzH0BMnPfzDx4gPs9GviPVd9/ASyJiInAocD7gDcDfwbMqVYpLS85tVrnLcB/Bm6KiF2Bb1ZjAngPcEdm/hZYAOwFTAE+Qe016+lvgY8CFzcwvDNj2zmJr/VYPq7q/1rgy9WyzwA7A28Erga66y8F7gMmAt8BPt9jOx8FjgY+BnQf1voPwK8yc2LVY2cDfe7wPCexY7omM2/tvpOZL0XtBO3JwL+j9kawD7Cll208DXwlMzMi7gP26GOfpfqXgF2qr14/tPTSZ2n7bwb+OTM3A/8aET/po8eSGdTeoO6u7u8KHAzcA9xJ7c3pFuDjmfmbAe6jnmOB66v+N0fEj6iN+1+AP1B7U74DOLuqf7ywvLftX5WZLwF3RMSvgbdTe8O9sEfNN6vbRwOzgV9U98dHxJjM/H11/7zMvK/BsZXOSfxDZv4hIm4AumckxwKfyMw/ANdWs5l9qH3QOChrF6DbPpguy8wNEbGKbf/X7gb+S0R8FvhedQ5KfXAmsWNa2fNORLwFWA5sAv4r8MsGtvHz3HZ1yEauElmqXwV8C/gI8Ne9baCPPuttP7bb1x8a6LPuroH/W80K9gUmVT0DvJ/aJ95pwAPVrKOZcrvbmZm/pjY7WgGcSC00KC0fwPafB34WEdOohdJt1eMBfKzH87A/8PIrK2e+6v/VAEX17068+vXa/v/Yq+5HxBsi4uQeix7fvi4z76Q241wLXBIRn2tCv6OeISGAw4A11A5BTaP2JtiX/l4++DX1ETEZOIDap8HDM/ORQfRZr5+7gWMjYo+IOBx4Rz977rYSOCwipkXELtTefI+JiD8CHgB+TO2T9xZqh6O6bYyIN0fE2Ijoa6ZVz1LgpOoN8K3AnwB3RsSfUnsObgE+Dbwrauou72P7H63ON7wHeEM1HqjNHv4T8Fhmvlgt+y5wckTsEhHvAB6h+e8h8yNiJ+DDwA979Pnx6hzKycDPMnMjcDvw8armw8BxPbZT7//bhcAJmbkYuJLaDFF9MCQEtW9+qB2yOYHasf0/bsN+f0nt/+CTEbEmIr4TEb0FVL/6zMwfAF8HfgZ8CXhoIE1m5jPAacCt1ELqrsz8x8x8AbgC+Ek1lhVsOyQF8FfAD4Cn6DugPhDbfj9jS0T8ZWZ+F7gOuL/a96mZ+TTwfeA3wLpqn39VzaJKy0uuqXr/f9RmQ8dX5x4A/qka87d61C+i9pz/HLgRODEzX2Zgep6TWF+dPwLYTO05Pplth8u+QG2GsY7aOYYTq+VnA++MiKeo/X/4yz72uRh4X0Q8A3yq2q76EP49CQ2ViHg/8P7MPC0idqb2RvWzzLx0iFvTEIiILmBhZnYNcSvqwZmEhtI9wNTqk+AT1A493Ti0LUnqyZmEJKnImYQkqciQkCQVjapfpttnn31yypQpQ92GJI0oq1ev/lVm1v0dn1EVElOmTGHVqlVD3YYkjSgR8UTpMQ83SZKKDAlJUpEhIUkqGlXnJCQNL1u3bmXt2rW89NJLQ92KgHHjxjFp0iTGjh3b8DqGhKSWWbt2La973euYMmUKvV9rUK2WmWzcuJG1a9ey//77971CxcNNklrmpZdeYu+99zYghoGIYO+99+73rM6QkNRSBsTwMZDXwpCQJBUZEpJGrcsvv5zOzk7Gjx9PZ2cnN998c7+3cfbZZze1ri8LFy7k+uuvb8q2msET15JGrTPPPJMzzzyTAw88kK6urgFt40tf+lJT60YaQ0JSW3zunx7koSefa+o2D9rv9Xz23x/c7/U6Ozs54ogjuP/++7n99tvZsmULxx13HM8//zwHHnggS5YseVVtd8AsXLiQrVu3smLFCp577jluu+029t1334bq9thjD+bNm8emTZt4y1vewvTp0/nMZz7TUL+//e1vmT9/Pk8++SSTJk1iyZIlvPzyyxx//PE899xz7L333tx0001s3br1NcvGjBnc27yHmyTtcFauXMnMmTO5/fbbAXjqqac466yz+O53v8uaNWt4+umni+s+9thjLF++nHnz5nHHHXc0XPfII48wadIk7rzzTh577LGGAwLgqquuYvr06Xz/+99n6tSpXHPNNTz00EPstNNOLF++nI985CNs2bKl7rLBciYhqS0G8om/VaZPn868efNeuT927FiuvvpqlixZwqZNm3jxxReL655yyikATJ48md/97ncN173xjW9k9erVzJo1i09+8pP96vehhx56pd8ZM2awdOlSzjjjDKZPn84xxxzD1KlTmTt3Locffvhrlg2WMwlJO5zdd9/9VfcXL17Mcccdxw033MBuu+3W67p9PV6qu+2227jgggu46667OOmkk/rV78EHH8zKlSuB2izo4IMP5r777uPII49k2bJlbN68mRUrVtRdNliGhKQd3pw5c7j44ouZPXs2AOvWrWv6Pg477DDOOussZs+ezQknnMADDzxQrL3wwgvp6Oigo6ODyy+/nNNOO40HH3yQWbNm8eijjzJ//nymTJnCl7/8Zd797nezfv16Ojo66i4brFH1N647OjrSvychDR8PP/wwb3vb24a6jWHhqquu4oYbbmDs2LGMHTuWc845h87Ozrb3Ue81iYjVmVk3UTwnIUltsGDBAhYsWDDUbfSbh5skSUWGhCSpyJCQJBUZEpKkIkNC0qg12Av83Xvvvdx777291gy3C/I1mz/dJGnUGuwF/roD4tBDD21qXyOJISGpPZaeC+t/0txt7vt2OPa/92uVF154gVNOOYVnnnmGt7/97XzlK1/hxRdffM2F8S644IJXZh7XXXcd3/ve9xrex1BekK/Zhlc3ktRiixYtYvr06SxcuJB58+Zx//33s3Xr1lcujHfrrbeyZcsWLr74YqZNmwbA/Pnz+7WP7gvy3XDDDSxcuJBrrrmGI4444jX7ePzxx1+z7A1veEPzBz0IhoSk9ujnJ/5W+elPf8oPf/hDurq6ePbZZ1m3bh1z585t6oXxhvKCfM3WthPXEbE4Iu6KiPP7WxMREyPintZ3KWm0mzZtGmeffTZdXV1cdNFFTJ48uXhhvPHjx/PCCy8A0J9LGA3lBfmarS0hERHzgJ0zcyZwQERM7WfNF4Hx7ehV0ui2YMECli5dyqxZs7jyyit505veVLww3pw5c/j2t7/NkUce2esb+HC6IF+zteUCfxHxZeC2zPw/EXECMD4zlzRSExGzgQ8Cb83MzjrbPh04HWDy5MnvfOKJJ1o9HEkN8gJ/w09/L/DXrsNNuwHd197dBExspCYidgEuAM4tbTgzF2VmR2Z2TJgwoYktS5LaFRJb2Ha4aPfCfuvVnAtckZnPtrpBSa0xmv4cwUg3kNeiXSGxGjiqun0IsKbBmqOBT0REF3BoRFzd0i4lNdW4cePYuHGjQTEMZCYbN25k3Lhx/VqvXT8CewuwIiL2A44FToiIizLz/F5qZmTm17ofjIiuzDytTf1KaoJJkyaxdu1aNmzYMNStiFpoT5o0qV/rtO0v00XEnsAcYHlmrh9oTW/8y3SS1H/D4i/TZeZm4MbB1kiS2serwEqSigwJSVKRISFJKjIkJElFhoQkqciQkCQVGRKSpCJDQpJUZEhIkooMCUlSkSEhSSoyJCRJRYaEJKnIkJAkFRkSkqQiQ0KSVGRISJKKDAlJUpEhIUkqMiQkSUWGhCSpyJCQJBUZEpKkIkNCklRkSEiSigwJSVKRISFJKjIkJElFhoQkqciQkCQVtS0kImJxRNwVEec3WhMRe0TE0ohYFhE3R8Qu7epXktSmkIiIecDOmTkTOCAipjZYcxJwSWYeA6wH5rajX0lSzZg27acTuLG6vQw4Cni0r5rMvKLH4xOAZ1rXoiRpe+063LQbsK66vQmY2J+aiJgJ7JmZK7dfKSJOj4hVEbFqw4YNze1aknZw7QqJLcD46vbuhf3WrYmIvYDLgFPrbTgzF2VmR2Z2TJgwoalNS9KOrl0hsZraISaAQ4A1jdRUJ6pvAj6dmU+0uklJ0qu1KyRuAU6OiEuADwIPRsRFfdT8M/BR4HDgvIjoiogPtalfSRIQmdmeHUXsCcwBlmfm+oHW9KajoyNXrVo1uEYlaQcTEaszs6PeY+366SYyczPbfnppwDWSpPbxN64lSUWGhCSpyJCQJBUZEpKkIkNCklRkSEiSigwJSVKRISFJKjIkJElFhoQkqciQkCQVGRKSpCJDQpJUZEhIkooMCUlSkSEhSSoyJCRJRYaEJKnIkJAkFRkSkqQiQ0KSVGRISJKKDAlJUpEhIUkqMiQkSUWGhCSpqKGQiIidIuL1ETEmIt4bEa9rdWOSpKHX6EziJmAW8HfAacDNLetIkjRsNBoSe2fmd4CpmXkSML6FPUmSholGQ+I3EXELsDoi/hz4TetakiQNF2MarDseOCgzfxwRhwAfamFPkqRhotGZxO+AxyJiDLAX8If+7igiFkfEXRFxfn9qGllPktQabTlxHRHzgJ0zcyZwQERMbaSmkfUkSa3TrhPXncCN1e1lwFEN1vS5XkScHhGrImLVhg0b+tmWJKk37TpxvRuwrrq9CZjYYE2f62XmoszsyMyOCRMm9LMtSVJv2nXiegvbZh+7Uz+c6tU0sp4kqUUafdP9PdAREX8HHAE838/9rGbboaJDgDUN1jSyniSpRRqdSSwBHgNuA2ZU90/ux35uAVZExH7AscAJEXFRZp7fS80MIOsskyS1SaMhMSkzu0Ph9oj4fn92kpnPRUQnMAf4n5m5Hrivj5pfA9RbJklqj0ZD4qmI+DTwI2qf5tf2d0eZuZltP6nUcE0j60mSWqPRcxLzgeeADwDPAitb1I8kaRhpaCaRmb8DvtJ9PyLuBi5rVVOSpOHBHymVJBX1OpOIiBPrLaZ2/SZJ0ijX1+Gm0rWSrmt2I5Kk4afXkMjMz7WrEUnS8OM5CUlSkSEhSSoyJCRJRYaEJKnIkJAkFRkSkqQiQ0KSVGRISJKKDAlJUpEhIUkqMiQkSUWGhCSpyJCQJBUZEpKkIkNCklRkSEiSigwJSVKRISFJKjIkJElFhoQkqciQkCQVGRKSpCJDQpJUZEhIkooMCUlSUctDIiIWR8RdEXF+f+oiYo+IWBoRyyLi5ojYpdW9SpJeraUhERHzgJ0zcyZwQERM7UfdScAlmXkMsB6Y28peJUmvNabF2+8EbqxuLwOOAh5tpC4zr+jx+ATgmXo7iIjTgdMBJk+ePOiGJUnbNHUmERFfjYiu7i/gLGBd9fAmYGJh1d1KdRExE9gzM1fWWzEzF2VmR2Z2TJgwoRnDkCRVmjqTyMwzet6PiEuB8dXd3SmH0pZ6dRGxF3AZ8IFm9ilJakyrT1yvpnaICeAQYE2jddWJ6puAT2fmE61sUpJUX6vPSdwCrIiI/YBjgRkRcRBwYmae31sd8FHgcOC8iDgP+PvM/EaL+5Uk9RCZ2dodROwJzAGWZ+b6wdb1pqOjI1etWjWwRiVpBxURqzOzo95jrZ5JkJmb2faTS4OukyS1j79xLUkqMiQkSUWGhCSpyJCQJBUZEpKkIkNCklRkSEiSigwJSVKRISFJKjIkJElFhoQkqciQkCQVGRKSpCJDQpJUZEhIkooMCUlSkSEhSSoyJCRJRYaEJKnIkJAkFRkSkqQiQ0KSVGRISJKKDAlJUpEhIUkqMiQkSUWGhCSpyJCQJBUZEpKkIkNCklTU8pCIiMURcVdEnD+QuoiYGBH3tLZLSVI9LQ2JiJgH7JyZM4EDImLqAOq+CIxvZZ+SpPpaPZPoBG6sbi8DjupPXUTMBp4H1pd2EBGnR8SqiFi1YcOGJrQsSerW1JCIiK9GRFf3F3AWsK56eBMwsbDqbtvXRcQuwAXAub3tMzMXZWZHZnZMmDBh0GOQJG0zppkby8wzet6PiEvZdqhod8qhtKVO3bnAFZn5bEQ0s01JUoNafbhpNdsOMR0CrOlH3dHAJ6oZyaERcXXLupQk1dXUmUQdtwArImI/4FhgRkQcBJyYmef3VpeZX+t+MCK6MvO0FvcqSdpOS2cSmfkctZPSK4H3ZuavM/Oh7QKibt12j3e2sk9JUn2tnkmQmZvZ9pNLg66TJLWPv3EtSSoyJCRJRYaEJKnIkJAkFRkSkqQiQ0KSVGRISJKKDAlJUpEhIUkqMiQkSUWGhCSpyJCQJBUZEpKkIkNCklRkSEiSigwJSVKRISFJKjIkJElFhoQkqciQkCQVGRKSpCJDQpJUZEhIkooiM4e6h6aJiA3AE0PdxwDsA/xqqJtoM8c8+u1o44WRO+Y3Z+aEeg+MqpAYqSJiVWZ2DHUf7eSYR78dbbwwOsfs4SZJUpEhIUkqMiSGh0VD3cAQcMyj3442XhiFY/achCSpyJmEJKnIkJAkFRkSbRIRiyPirog4fyB1ETExIu5pbZfNM9DxRsQeEbE0IpZFxM0RsUt7Oh6cRsZbr6bR52k4GsiYR+rr222gr3O1fER9D3czJNogIuYBO2fmTOCAiJg6gLovAuNb3+3gDXK8JwGXZOYxwHpgbrv6HqhGxluvptHnaTga6JgZga9vt0GMuduI+R7uyZBoj07gxur2MuCo/tRFxGzgeWrfVCNBJwMcb2ZekZn/Ui2bADzToh6bqZO+x1uvppH1hqtOBjDmEfr6dutkYK/zSPwefoUh0QIR8dWI6Or+As4C1lUPbwImFlbdbfu6ajp+AXBuC1selGaOt8c2ZwJ7ZubK1nTdVMVx9FHTyHrD1UDHDIy417fbgMY8Er6HezNmqBsYjTLzjJ73I+JStk0zd6cczlvq1J0LXJGZz0ZEC7odvCaPl4jYC7gM+EDTm22NuuNooKaR9YargY55JL6+3QY65mH/PdybkfSfciRbzbap6SHAmn7UHQ18ovqEfmhEXN2yLptnwOOtPnXdBHw6M0fKxRobGW+9mkafp+FoQGMeoa9vt4G+ziPxe3ibzPSrxV/A64H7gEuAh4E9gIOAi/qq2+7xrqEeS6vHC3wc2Ax0VV8fGurxDGC8hzQ41l5f7+H8NYgxj7jXd7Bj3u7xrqEeR3+//I3rNomIPYE5wPLMLJ68arRuuHO8jdWM5PEPdMwj2Q45ZkNCklTiOQlJUpEhIUkqMiQkSUWGhDRAEbEwIh7u8YuEhw5yW51Na05qEn+ZThqcz2fm9UPdhNQqhoTUJBFxLbWfk58I3JOZZ0bErsC1wH7AWuAj1Gbw1wKTgGeBD1abmBMRf11tY+5o+PFJjXwebpIG57we16zaGfhmZh4J7B8R7wQWAA9k5nuAR4FTgdOB+zLzKOBbwPRqWwdm5izg28DsNo9DqsuQkAbn85nZmZmdwMvULssAcD8whdpvmv+oWrYSeBvwVuDuatm1wL9Wt/+h+vcXwIj6OwsavQwJqbneVf17KPA48CAwo1o2o7r/CHBEtewzwGnV7efb06LUOM9JSINzXkR0v8n/CTA+Ij4G3J2Z90bEw8C1EbEc+CXwBWqHpf53dYhqI7U/xDMiLyOt0c/LckhNUp24XpiZa4a4FalpDAlJUpHnJCRJRYaEJKnIkJAkFRkSkqQiQ0KSVPT/AR6Siqy4dHXNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_epoch = 50\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    print(f\"==== Epoch {i} ====\")\n",
    "    train_loss = train_model(model, train_dataloader)\n",
    "    test_loss = test_model(model, test_dataloader)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(range(1, num_epoch + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epoch + 1), test_losses, label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a33a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbd4cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ba52c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

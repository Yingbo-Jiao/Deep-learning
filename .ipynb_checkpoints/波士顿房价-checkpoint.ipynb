{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c7d7f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU可用\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 检查是否有可用的GPU\n",
    "if torch.cuda.is_available():\n",
    "    # 如果有可用的GPU，选择第一个GPU设备\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU可用\")\n",
    "else:\n",
    "    # 如果没有可用的GPU，使用CPU\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU不可用\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbe0cea9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# 数据预处理\n",
    "def encode_categorical(df):\n",
    "    label_encoder = LabelEncoder()\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column] = label_encoder.fit_transform(df[column])\n",
    "        elif df[column].dtype == 'float64' or df[column].dtype == 'int64':\n",
    "            df[column] = df[column].fillna(df[column].mean())\n",
    "    return df\n",
    "\n",
    "df1 = pd.read_csv('train.csv')\n",
    "df1 = encode_categorical(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f262afc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1168"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch.utils.data as Data\n",
    "import torch\n",
    "\n",
    "\n",
    "batch_sizes = 32\n",
    "\n",
    "x = df1.iloc[:,1:-1]\n",
    "y= df1.iloc[:,-1:]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2004)\n",
    "\n",
    "x_train_tensor = torch.FloatTensor(x_train.values)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values)\n",
    "x_test_tensor = torch.FloatTensor(x_test.values)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values)\n",
    "\n",
    "train_dataset = Data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = Data.TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "train_dataloader = Data.DataLoader(train_dataset,batch_sizes,shuffle=True)\n",
    "test_dataloader = Data.DataLoader(test_dataset,batch_sizes,shuffle=True)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a45ed41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(in_features, 40)  # nn.Module\n",
    "        self.linear_2 = nn.Linear(40, 10)\n",
    "        self.linear_3 = nn.Linear(10, out_features)\n",
    "        self.sigmoid = nn.Sigmoid()  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.sigmoid(x)  \n",
    "        x = self.linear_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.linear_3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e11e4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置优化器和损失函数\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LinearNet(79,1).to(device)\n",
    "loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd714e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "def train_model(model,dataloader):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    for idx,(x,y) in enumerate(dataloader):\n",
    "        y_pred = model(x)\n",
    "        cur_loss = loss(y_pred,y)\n",
    "        optimizer.zero_grad()\n",
    "        cur_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += cur_loss.item()\n",
    "    print(f\"train loss:{total_loss/len(train_dataset)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56efe6cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected a 'cuda' device type for generator but found 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-a16add41cf37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mEpoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEpoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-e52a40903011>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mcur_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    629\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_index\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[0midx_in_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx_in_batch\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                 \u001b[0midx_in_batch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandperm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandperm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\_device.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_device_constructors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'device'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'device'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;31m# NB: This is directly called from C++ in torch/csrc/Device.cpp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected a 'cuda' device type for generator but found 'cpu'"
     ]
    }
   ],
   "source": [
    "Epoch = 100\n",
    "for i in range(Epoch):\n",
    "    train_model(model,train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4aff9460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证模型\n",
    "def test_model(model, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.\n",
    "    for idx, (x, y) in enumerate(dataloader):\n",
    "        y_pred = model(x)\n",
    "        cur_loss = loss(y_pred, y)\n",
    "        total_loss += cur_loss.item()\n",
    "    print(f\"Test loss: {total_loss/len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4d04abf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Epoch 0 ====\n",
      "train loss:1211683392.8767123\n",
      "Test loss: 1410238218.5205479\n",
      "==== Epoch 1 ====\n",
      "train loss:1208887553.7534246\n",
      "Test loss: 1424549439.1232877\n",
      "==== Epoch 2 ====\n",
      "train loss:1210246776.9863014\n",
      "Test loss: 1827541083.1780822\n",
      "==== Epoch 3 ====\n",
      "train loss:1204169854.2465754\n",
      "Test loss: 1409016242.8493152\n",
      "==== Epoch 4 ====\n",
      "train loss:1210650806.3561645\n",
      "Test loss: 1433728000.0\n",
      "==== Epoch 5 ====\n",
      "train loss:1207500782.4657533\n",
      "Test loss: 1844194710.7945206\n",
      "==== Epoch 6 ====\n",
      "train loss:1204756536.109589\n",
      "Test loss: 1398098424.9863014\n",
      "==== Epoch 7 ====\n",
      "train loss:1208391690.5205479\n",
      "Test loss: 1413409413.260274\n",
      "==== Epoch 8 ====\n",
      "train loss:1207075489.3150685\n",
      "Test loss: 1384307150.9041095\n",
      "==== Epoch 9 ====\n",
      "train loss:1209338017.3150685\n",
      "Test loss: 1488872938.958904\n",
      "==== Epoch 10 ====\n",
      "train loss:1207906167.2328768\n",
      "Test loss: 1422450337.3150685\n",
      "==== Epoch 11 ====\n",
      "train loss:1210043216.6575344\n",
      "Test loss: 1451432258.630137\n",
      "==== Epoch 12 ====\n",
      "train loss:1203827296.4383562\n",
      "Test loss: 1371583081.2054794\n",
      "==== Epoch 13 ====\n",
      "train loss:1204185400.109589\n",
      "Test loss: 1457730265.4246576\n",
      "==== Epoch 14 ====\n",
      "train loss:1206243343.7808218\n",
      "Test loss: 1570240736.4383562\n",
      "==== Epoch 15 ====\n",
      "train loss:1207626541.589041\n",
      "Test loss: 1458564530.8493152\n",
      "==== Epoch 16 ====\n",
      "train loss:1208849799.0136986\n",
      "Test loss: 1427262183.4520547\n",
      "==== Epoch 17 ====\n",
      "train loss:1206282282.0821917\n",
      "Test loss: 1421685570.630137\n",
      "==== Epoch 18 ====\n",
      "train loss:1208424076.2739725\n",
      "Test loss: 1431105465.8630137\n",
      "==== Epoch 19 ====\n",
      "train loss:1209885319.0136986\n",
      "Test loss: 1451235110.5753424\n",
      "==== Epoch 20 ====\n",
      "train loss:1206243996.0547945\n",
      "Test loss: 1393390269.369863\n",
      "==== Epoch 21 ====\n",
      "train loss:1204132225.7534246\n",
      "Test loss: 1476011449.8630137\n",
      "==== Epoch 22 ====\n",
      "train loss:1208785393.9726028\n",
      "Test loss: 1411455032.109589\n",
      "==== Epoch 23 ====\n",
      "train loss:1204790433.3150685\n",
      "Test loss: 1796842496.0\n",
      "==== Epoch 24 ====\n",
      "train loss:1206060100.3835616\n",
      "Test loss: 1434245709.1506848\n",
      "==== Epoch 25 ====\n",
      "train loss:1210708721.9726028\n",
      "Test loss: 1463905546.5205479\n",
      "==== Epoch 26 ====\n",
      "train loss:1210192326.1369863\n",
      "Test loss: 1538918168.5479453\n",
      "==== Epoch 27 ====\n",
      "train loss:1209115125.4794521\n",
      "Test loss: 1407350503.4520547\n",
      "==== Epoch 28 ====\n",
      "train loss:1211967228.4931507\n",
      "Test loss: 1438413550.4657533\n",
      "==== Epoch 29 ====\n",
      "train loss:1202144422.5753424\n",
      "Test loss: 1394142074.739726\n",
      "==== Epoch 30 ====\n",
      "train loss:1203750264.9863014\n",
      "Test loss: 1436928939.8356164\n",
      "==== Epoch 31 ====\n",
      "train loss:1212657276.4931507\n",
      "Test loss: 1369715487.5616438\n",
      "==== Epoch 32 ====\n",
      "train loss:1209076064.4383562\n",
      "Test loss: 1392414656.8767123\n",
      "==== Epoch 33 ====\n",
      "train loss:1208375325.8082192\n",
      "Test loss: 1413815850.0821917\n",
      "==== Epoch 34 ====\n",
      "train loss:1203969081.8630137\n",
      "Test loss: 1491395506.8493152\n",
      "==== Epoch 35 ====\n",
      "train loss:1206311583.5616438\n",
      "Test loss: 1444356208.2191782\n",
      "==== Epoch 36 ====\n",
      "train loss:1205349114.739726\n",
      "Test loss: 1443668746.5205479\n",
      "==== Epoch 37 ====\n",
      "train loss:1206494364.0547945\n",
      "Test loss: 1436750876.0547945\n",
      "==== Epoch 38 ====\n",
      "train loss:1208659876.8219178\n",
      "Test loss: 1622543640.5479453\n",
      "==== Epoch 39 ====\n",
      "train loss:1208219709.369863\n",
      "Test loss: 1457811820.7123287\n",
      "==== Epoch 40 ====\n",
      "train loss:1206191249.5342467\n",
      "Test loss: 1429882844.9315069\n",
      "==== Epoch 41 ====\n",
      "train loss:1208022580.6027398\n",
      "Test loss: 1409439365.260274\n",
      "==== Epoch 42 ====\n",
      "train loss:1203262236.0547945\n",
      "Test loss: 1435536797.8082192\n",
      "==== Epoch 43 ====\n",
      "train loss:1212701236.6027398\n",
      "Test loss: 1858517405.8082192\n",
      "==== Epoch 44 ====\n",
      "train loss:1210225914.739726\n",
      "Test loss: 1546628110.0273972\n",
      "==== Epoch 45 ====\n",
      "train loss:1207353379.0684931\n",
      "Test loss: 1385709603.0684931\n",
      "==== Epoch 46 ====\n",
      "train loss:1205279077.69863\n",
      "Test loss: 1570252147.7260275\n",
      "==== Epoch 47 ====\n",
      "train loss:1206026234.739726\n",
      "Test loss: 1415049615.7808218\n",
      "==== Epoch 48 ====\n",
      "train loss:1211265381.69863\n",
      "Test loss: 1417754736.2191782\n",
      "==== Epoch 49 ====\n",
      "train loss:1209705191.4520547\n",
      "Test loss: 1516461673.2054794\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 50\n",
    "for i in range(num_epoch):\n",
    "    print(f\"==== Epoch {i} ====\")\n",
    "    train_model(model, train_dataloader)\n",
    "    test_model(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7fc4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a33a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
